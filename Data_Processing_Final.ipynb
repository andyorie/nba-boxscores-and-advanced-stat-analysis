{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8786a2d8",
   "metadata": {},
   "source": [
    "# Title: NBA Games\n",
    "## Author: Andy Orie\n",
    "## Date: 5th July 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494f6da",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "    1. Read in the csv files, set the index to a common attribute across all the dataset to allow for combining.\n",
    "    2. Investigate and then Clean the data by removing redundant and un-necessary columns.\n",
    "    3. Combine the files and save for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Settings and Imported Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from matplotlib import rcParams\n",
    "# Specify the figure size in inches, for both X, and Y axes\n",
    "rcParams['figure.figsize'] = 12,5\n",
    "\n",
    "from matplotlib import style\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9485061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import script 'chkdir.py' to check the working directory. \"Y\" if you are in the correct working directory, else \"N\".\n",
    "\n",
    "import chkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv files to panda dataframes\n",
    "\n",
    "games = pd.read_csv('games.csv', index_col=['GAME_DATE_EST'], parse_dates=True)\n",
    "\n",
    "teams = pd.read_csv('teams.csv', index_col=['TEAM_ID'])\n",
    "\n",
    "players = pd.read_csv('players.csv', index_col=['TEAM_ID'])\n",
    "\n",
    "ranking = pd.read_csv('ranking.csv', index_col=['TEAM_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c402bba8",
   "metadata": {},
   "source": [
    "# Games Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246123d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the data in the 'games' dataframe\n",
    "\n",
    "print('The shape of the \"games\" dataframe is: ',games.shape)\n",
    "print(100*'-')\n",
    "games.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the games dataframe data types to see if any need to be changed.\n",
    "\n",
    "print(games.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the data in two of the columns are the same. Let's check.\n",
    "\n",
    "print('There are {:0d} unique elements in the HOME_TEAM_ID column'.format(games['HOME_TEAM_ID'].nunique()))\n",
    "print()\n",
    "print('There are {:0d} unique elements in the TEAM_ID_home column'.format(games['TEAM_ID_home'].nunique()))\n",
    "print()\n",
    "print('Are the elements in the HOME_TEAM_ID and TEAM_ID_home columns the same?:', games['HOME_TEAM_ID'].equals(games['TEAM_ID_home']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It appears the 'GAME_STATUS_TEXT' column has 'Final' as the only value. Let's check.\n",
    "\n",
    "print(f'There are', games['GAME_STATUS_TEXT'].value_counts(), 'values under the GAME_STATUS_TEXT column')\n",
    "print()\n",
    "print('There are {:0d} unique values in the GAME_STATUS_TEXT column'.format(games['GAME_STATUS_TEXT'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2306d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the data in another two of the columns are the same. Let's check.\n",
    "\n",
    "print('There are {:0d} unique elements in the VISITOR_TEAM_ID column'.format(games['VISITOR_TEAM_ID'].nunique()))\n",
    "print()\n",
    "print('There are {:0d} unique elements in the TEAM_ID_away column'.format(games['TEAM_ID_away'].nunique()))\n",
    "print()\n",
    "print('Are the elements in the VISITOR_TEAM_ID and TEAM_ID_away columns the same?:', games['VISITOR_TEAM_ID'].equals(games['TEAM_ID_away']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us remove the reduntant columns of TEAM_ID_home, TEAM_ID_away and GAMES_STATUS_TEXT columns.\n",
    "\n",
    "games1 = games.drop(['TEAM_ID_home', 'TEAM_ID_away','GAME_STATUS_TEXT'], axis=1)\n",
    "print('The \"games\" dataframe previous shape was:', games.shape)\n",
    "print()\n",
    "print('Now, the \"games1\" dataframe has a new shape of:', games1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many NaN values there are in the games1 dataframe\n",
    "\n",
    "num_null = games1.isnull().sum().sum()\n",
    "print('There are {:0d} NaN values inside the \"games1\" dataframe'.format(num_null))\n",
    "print(100*'-')\n",
    "print('The # of nulls in the columns are: \\n',games1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e39917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There appears to be 99 records with NaN values. Let's remove these since they are much less than 10% of the data.\n",
    "\n",
    "games2 = games1.dropna(axis=0, inplace=False)\n",
    "\n",
    "print('The new shape of the dataframe after dropping NaN is:', games2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c353526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the name of the index\n",
    "\n",
    "print(games2.index.names)\n",
    "print(100*'-')\n",
    "\n",
    "# Let's rename the index to Game_Date\n",
    "\n",
    "games2.index.names = ['GAME_DATE']\n",
    "\n",
    "games2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac90c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the period of time considered in the \"games2\" dataframe?\n",
    "\n",
    "print(sorted(list(games2.index.year.unique())))\n",
    "print(100*'-')\n",
    "print(f'There are {len(games2.index.year.unique())} seasons considered in the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05961f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the index time stamp into years, months and day columns.\n",
    "\n",
    "games2['GM_YR'] = games2.index.year\n",
    "games2['GM_MTH'] = games2.index.month\n",
    "games2['GM_DAY'] = games2.index.day\n",
    "games2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d132a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reorder the columns so our new date info columns (i.e. last 3 columns) are to the front.\n",
    "\n",
    "cols = games2.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "games2 = games2[cols]\n",
    "games2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d90a5",
   "metadata": {},
   "source": [
    "# Teams Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the data in the 'teams' dataframe\n",
    "\n",
    "print('The shape of the \"teams\" dataframe is: ',teams.shape)\n",
    "print(100*'-')\n",
    "teams.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the teams dataframe data types.\n",
    "\n",
    "print(teams.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look at the data under the 'LEAGUE_ID' column.\n",
    "\n",
    "print('There is {:0d} unique value under the \"LEAGUE_ID\" column'.format(teams['LEAGUE_ID'].nunique()))\n",
    "print()\n",
    "print('There a total of', teams['LEAGUE_ID'].value_counts().sum(), 'counts inside the \"LEAGUE_ID\" column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep only a few columns for our initial assessment since I don't need the other features at this time.\n",
    "\n",
    "teams = teams[['ABBREVIATION', 'NICKNAME', 'CITY', 'ARENACAPACITY', 'HEADCOACH']]\n",
    "teams.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many teams are there? and what are their names?\n",
    "\n",
    "print('There are {:0d} teams in the dataset'. format(teams['NICKNAME'].nunique()))\n",
    "print(100*'-')\n",
    "print(teams['NICKNAME'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the \"teams\" dataframe.\n",
    "\n",
    "nan_teams = teams.isnull().sum().sum()\n",
    "print('There are {:0d} NaN values in the \"teams\" dataframe'.format(nan_teams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns with NaN values.\n",
    "\n",
    "print(teams.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows with NaN values under the ARENACAPACITY column.\n",
    "\n",
    "teams[teams['ARENACAPACITY'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any Zero values in our data?\n",
    "\n",
    "teams.isin([0]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What column has the zero values?\n",
    "\n",
    "teams.isin([0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which team has zero Arena Capacity?\n",
    "\n",
    "teams[teams['ARENACAPACITY'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the zero Arena Capacity for Magic with the mean.\n",
    "\n",
    "teams['ARENACAPACITY'] = teams['ARENACAPACITY'].replace(to_replace=0, value=teams['ARENACAPACITY'].mean(), inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e52508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill all NaN with the mean of the Area Capacity.\n",
    "\n",
    "teams.fillna(teams.mean(), inplace=True)\n",
    "\n",
    "# Let's verify the changes were made.\n",
    "\n",
    "teams.groupby(['NICKNAME']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a copy of the 'teams' dataframe so we can combine it with the 'players' dataframe.\n",
    "comb_df = teams.copy()\n",
    "\n",
    "print('The \"comb_df\" has a shape of:', comb_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f68d46",
   "metadata": {},
   "source": [
    "# Players Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the data in the 'players' dataframe\n",
    "\n",
    "print('The \"players\" dataframe has a shape of:', players.shape)\n",
    "print(100*'-')\n",
    "players.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e13384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Nulls/ NaN values are there in the dataset?\n",
    "\n",
    "players.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc321822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any Zero values in our dataset?\n",
    "\n",
    "players.isin([0]).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the 'teams' and 'players' dataframes on the index using Approach1: \n",
    "# the join(how='outer') to include all rows.\n",
    "\n",
    "comb_df = comb_df.join(players, how='outer')\n",
    "\n",
    "print('The shape of the combined dataframes is:',comb_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322dbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the 'teams' and 'players' dataframes on the index using Approach2: the pd.merge() to include all rows.\n",
    "\n",
    "#comb_df1 = pd.merge(teams,players,how='outer',left_index=True, right_index=True)\n",
    "\n",
    "#print('The shape of the combined dataframes is:',comb_df1.shape)\n",
    "#print()\n",
    "#comb_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the joined dataset.\n",
    "\n",
    "comb_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the games dataframe data types to see if any need to be changed.\n",
    "\n",
    "comb_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683579c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many and What Seasons are there in the comb_df dataset?\n",
    "\n",
    "print('There are {:0d} seasons in the comb_df dataset'.format(comb_df['SEASON'].nunique()))\n",
    "print()\n",
    "\n",
    "period = sorted(list(comb_df['SEASON'].unique()))\n",
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's play around with the data for specific teams and years.\n",
    "# Get specific data based on User input for the team nickname and the season.\n",
    "\n",
    "team_listing = list(comb_df['NICKNAME'].unique())\n",
    "period = list(comb_df['SEASON'].unique())\n",
    "\n",
    "prompt = 'Please enter the team nickname you want to look at from the list shown, or \"q\" to quit? '\n",
    "prompt_2 = 'What season would you like to look at between 2009 to 2019? '\n",
    "\n",
    "while True:\n",
    "    print('Here are the teams to choose from: \\n', team_listing)\n",
    "    print()\n",
    "    team_name = input(prompt)\n",
    "    print()\n",
    "    if team_name=='q':\n",
    "        break\n",
    "    if team_name.title() not in team_listing:\n",
    "        print('ALERT - Your team is not in the shown list. Please try again.')\n",
    "        print()\n",
    "        continue\n",
    "    chk_season = int(input(prompt_2))\n",
    "    if chk_season not in period:\n",
    "        print('ALERT - Your year is not between 2009 and 2019. Please try again.')\n",
    "        print()\n",
    "        continue\n",
    "    else:\n",
    "        print(df1.get_group((team_name.title(), chk_season)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef53919",
   "metadata": {},
   "source": [
    "# Ranking Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d86824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the \"ranking\" dataframe\n",
    "\n",
    "print('The \"ranking\" dataframe has a shape of:', ranking.shape)\n",
    "print()\n",
    "print(ranking.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca001e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d20344",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e10d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN values\n",
    "\n",
    "nan_ranking = ranking.isnull().sum().sum()\n",
    "print('There are {:0d} NaN values inside the dataframe'.format(nan_ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f198ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which columns have NaN values\n",
    "\n",
    "rank_cols = ranking.columns\n",
    "print(ranking[rank_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There is therefore', ranking.shape[0]-nan_ranking, 'non-NaN values under the RETURNTOPLAY column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the number of unique values under the 'RETURNTOPLAY'.\n",
    "\n",
    "print('There are -', ranking['RETURNTOPLAY'].value_counts(), '- values under the RETURNTOPLAY column')\n",
    "print()\n",
    "print('There are {:0d} unique values in the RETURNTOPLAY column'.format(ranking['RETURNTOPLAY'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The unique SEASON_ID values are: ',ranking['SEASON_ID'].unique())\n",
    "print()\n",
    "print('There are {:1d} unique values in the SEASON_ID column'.format(ranking['SEASON_ID'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a copy of the ranking dataframe.\n",
    "\n",
    "ranking_2 = ranking.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's populate a new list called 'my_lst' with the year extracted from the SEASON_ID column.\n",
    "my_ls = []\n",
    "\n",
    "start_yr = 2002\n",
    "\n",
    "for yr1 in ranking_2['SEASON_ID']:\n",
    "    if int(str(yr1)[-4:]) == start_yr:\n",
    "        my_ls.append(start_yr)\n",
    "    elif int(str(yr1)[-4:]) == 2003:\n",
    "        my_ls.append(2003)\n",
    "    elif int(str(yr1)[-4:]) == 2004:\n",
    "        my_ls.append(2004)\n",
    "    elif int(str(yr1)[-4:]) == 2005:\n",
    "        my_ls.append(2005)\n",
    "    elif int(str(yr1)[-4:]) == 2006:\n",
    "        my_ls.append(2006)\n",
    "    elif int(str(yr1)[-4:]) == 2007:\n",
    "        my_ls.append(2007)\n",
    "    elif int(str(yr1)[-4:]) == 2008:\n",
    "        my_ls.append(2008)\n",
    "    elif int(str(yr1)[-4:]) == 2009:\n",
    "        my_ls.append(2009)\n",
    "    elif int(str(yr1)[-4:]) == 2010:\n",
    "        my_ls.append(2010)\n",
    "    elif int(str(yr1)[-4:]) == 2011:\n",
    "        my_ls.append(2011)\n",
    "    elif int(str(yr1)[-4:]) == 2012:\n",
    "        my_ls.append(2012)\n",
    "    elif int(str(yr1)[-4:]) == 2013:\n",
    "        my_ls.append(2013)\n",
    "    elif int(str(yr1)[-4:]) == 2014:\n",
    "        my_ls.append(2014)\n",
    "    elif int(str(yr1)[-4:]) == 2015:\n",
    "        my_ls.append(2015)\n",
    "    elif int(str(yr1)[-4:]) == 2016:\n",
    "        my_ls.append(2016)\n",
    "    elif int(str(yr1)[-4:]) == 2017:\n",
    "        my_ls.append(2017)\n",
    "    elif int(str(yr1)[-4:]) == 2018:\n",
    "        my_ls.append(2018)\n",
    "    elif int(str(yr1)[-4:]) == 2019:\n",
    "        my_ls.append(2019)\n",
    "    elif int(str(yr1)[-4:]) == 2020:\n",
    "        my_ls.append(2020)\n",
    "    elif int(str(yr1)[-4:]) == 2021:\n",
    "        my_ls.append(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452661d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's insert the years in 'my_ls' as a new column at index 4 in the ranking_2 dataframe.\n",
    "\n",
    "ranking_2.insert(4, 'SEASON', my_ls)\n",
    "ranking_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b824e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(ranking_2['TEAM'].unique()), 'teams in our dataset.')\n",
    "\n",
    "print()\n",
    "\n",
    "print(list(ranking_2['TEAM'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only take a few columns\n",
    "\n",
    "new_ranking = ranking_2[['CONFERENCE', 'TEAM', 'G', 'W', 'L', 'W_PCT', 'HOME_RECORD', 'ROAD_RECORD', 'SEASON']]\n",
    "new_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2132735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What period does the new_ranking dataset cover?\n",
    "\n",
    "print('There are {:0d} seasons in the new_ranking dataset'.format(new_ranking['SEASON'].nunique()))\n",
    "print()\n",
    "print(sorted(list(new_ranking['SEASON'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a964f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What period does the comb_df dataset cover?\n",
    "\n",
    "print('There are {:0d} seasons in the new_ranking dataset'.format(comb_df['SEASON'].nunique()))\n",
    "print()\n",
    "print(sorted(list(comb_df['SEASON'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd291da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make the index into a column for easy merging\n",
    "\n",
    "new_ranking.reset_index(inplace=True)\n",
    "new_ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8db94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make the index into a column for easy merging in the comb_df.\n",
    "\n",
    "comb_df.reset_index(inplace=True)\n",
    "comb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the 'new_ranking' and 'comb_df' dataframes on the index using Approach2: the pd.merge() to include all rows.\n",
    "\n",
    "comb_df2 = pd.merge(new_ranking,comb_df,how='outer',on = ['TEAM_ID', 'SEASON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e944f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the modified dataframe \"games2\" as \"games_mod.csv\" for later use.\n",
    "\n",
    "games2.to_csv('games_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739933b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the combined dataframe \"comb_df2\" as \"team_players_ranking.csv\" for later use.\n",
    "\n",
    "comb_df2.to_csv('team_players_ranking.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0d84e",
   "metadata": {},
   "source": [
    "*End of Code*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
